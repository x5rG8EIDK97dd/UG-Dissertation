library(dplyr)
library(tidyr)
library(purrr)
library(sf)
library(spdep)
library(missForest)
library(doParallel)
library(osmdata)

setwd("C:/Users/joema/OneDrive/Year 3/Dissertation/Gentrification Index")


# loading in compiled IMD database from the core script.
m <- read.csv("m.csv") 
m <- m %>% select(-IMD2007)


hp <- read.csv("HPSSA Dataset 46 - Median price paid for residential properties by LSOA.csv")
hpborough <- read.csv("land-registry-house-prices-borough.csv")

LSOA11CD = c(m$LSOA11CD)

# Subset to London LSOAs
hp <- hp[hp$LSOA.code %in% LSOA11CD,]
colnames(hp)[3] <- "LSOA11CD"
colnames(m)[1] <- "LSOA11CD"

# Clean and convert
hp <- data.frame(lapply(hp, function(x) {
  if (is.character(x) | is.factor(x)) gsub(",", "", x) else x
})) %>% mutate_all(~na_if(.x, ":"))
hp[, 5:ncol(hp)] <- lapply(hp[, 5:ncol(hp)], function(x) as.numeric(as.character(x)))

# Load and align Greater London shapefile
lsoa_sf <- st_read("Spatial Data/statistical-gis-boundaries-london/ESRI/LSOA_2011_London_gen_MHW.shp")
lsoa_sf <- st_transform(lsoa_sf, 27700)
lsoa_sf <- lsoa_sf[match(hp$LSOA11CD, lsoa_sf$LSOA11CD), ]

# Spatial weights
coords <- st_centroid(st_geometry(lsoa_sf)) %>% st_coordinates()
nb <- dnearneigh(coords, 0, 2500)
distances <- nbdists(nb, coords)

# inverse decay function to weight closer LSOA house prices by more
inv_distances <- lapply(distances, function(d) 1 / (d + 1))  
#nb <- poly2nb(lsoa_sf, queen = TRUE)
lw <- nb2listw(nb, glist = inv_distances, style = "W")

# Get distance to stations
stations <- opq("Greater London") %>%
  add_osm_feature(key = "railway", value = "station") %>%
  osmdata_sf()
stations_sf <- stations$osm_points %>% st_transform(27700)
lsoa_centroids <- st_centroid(lsoa_sf)
station_dists <- st_distance(lsoa_centroids, stations_sf)
dist_to_station_vec <- as.numeric(apply(station_dists, 1, min)) / 1000

#  DETECT COLUMNS TO IMPUTE 
dec_cols <- grep("Year\\.ending\\.Dec\\.(2008|2009|2010|2011|2012|2013|2014|2015|2016|2017|2018|2019)", names(hp), value = TRUE)
jun_cols <- grep("Year\\.ending\\.Jun\\.(2013|2016|2019)", names(hp), value = TRUE)
hp_cols <- c(dec_cols, jun_cols)
hp_values <- hp[, c("LSOA11CD", hp_cols)]

#  Pivot HP to long 
hp_long <- hp_values %>%
  pivot_longer(-LSOA11CD, names_to = "Period", values_to = "HousePrice") %>%
  mutate(Year = as.integer(gsub(".*(\\d{4})$", "\\1", Period)))

#  Pivot IMD to long 
imd_long <- m %>%
  select(LSOA11CD, starts_with("IMD")) %>%
  pivot_longer(-LSOA11CD, names_to = "IMD_Year", values_to = "IMD") %>%
  mutate(Year = as.integer(gsub("IMD", "", IMD_Year))) %>%
  select(-IMD_Year)


#  Create spatial lags with MSOA and borough fallback 
hp_matrix <- hp[, hp_cols]
rownames(hp_matrix) <- hp$LSOA11CD
colnames(hp_matrix) <- gsub("Year\\.ending\\.", "", colnames(hp_matrix))
colnames(hp_matrix) <- gsub("\\.", "_", colnames(hp_matrix))

lag_hp <- data.frame(matrix(nrow = nrow(hp_matrix), ncol = 0))
msoa_ids <- lsoa_sf$MSOA11CD
borough_ids <- lsoa_sf$LAD11CD

for (col in colnames(hp_matrix)) {
  temp_col <- hp_matrix[[col]]
  temp_filled <- temp_col
  
  msoa_fill_count <- 0
  borough_fill_count <- 0
  fallback_fill_count <- 0
  
  for (msoa in unique(msoa_ids)) {
    idx <- which(msoa_ids == msoa)
    msoa_mean <- mean(temp_col[idx], na.rm = TRUE)
    missing_idx <- idx[is.na(temp_col[idx])]
    temp_filled[missing_idx] <- msoa_mean
    msoa_fill_count <- msoa_fill_count + length(missing_idx)
  }
  
  for (borough in unique(borough_ids)) {
    idx <- which(borough_ids == borough)
    borough_mean <- mean(temp_filled[idx], na.rm = TRUE)
    missing_idx <- idx[is.na(temp_filled[idx])]
    temp_filled[missing_idx] <- borough_mean
    borough_fill_count <- borough_fill_count + length(missing_idx)
  }
  
  still_na_idx <- which(!is.finite(temp_filled))
  temp_filled[still_na_idx] <- mean(temp_col, na.rm = TRUE)
  fallback_fill_count <- length(still_na_idx)
  
  cat(paste0("[", col, "] Filled with MSOA mean: ", msoa_fill_count,
             ", borough mean: ", borough_fill_count,
             ", fallback to overall mean: ", fallback_fill_count, "\n"))
  
  lag_hp[[paste0("lag_", col)]] <- lag.listw(lw, temp_filled)
}
lag_hp$LSOA11CD <- rownames(hp_matrix)

lag_hp_long <- lag_hp %>%
  pivot_longer(-LSOA11CD, names_to = "LagPeriod", values_to = "lag_hp") %>%
  mutate(Period = gsub("_", ".", sub("lag_", "Year.ending.", LagPeriod))) %>%
  select(-LagPeriod)


#  Combine into long format 
long_df <- hp_long %>%
  left_join(imd_long, by = c("LSOA11CD", "Year")) %>%
  left_join(lag_hp_long, by = c("LSOA11CD", "Period")) %>%
  mutate(dist_to_station = dist_to_station_vec[match(LSOA11CD, hp$LSOA11CD)])

str(long_df)

long_df$Year <- as.numeric(long_df$Year)

long_df <- as.data.frame(long_df)

impute_df <- long_df[, c("Year", "HousePrice", "IMD", "lag_hp", "dist_to_station")]

set.seed(123)  # for reproducible results

#  Hyperparameter Tuning for missForest 
param_grid <- expand.grid(
  ntree = c(50, 100, 200),
  mtry = c(2, 3, 4),
  maxnodes = c(10, 20, 30),
  nodesize = c(1, 5, 9)
)

# Function to evaluate missForest model
evaluate_rf_model <- function(ntree, mtry, maxnodes, nodesize, data) {
  # Ensure nodesize is passed as a vector of length 2
  nodesize_vector <- c(nodesize, nodesize)
  
  rf_model <- missForest(
    data,
    ntree = ntree,
    mtry = mtry,
    maxnodes = maxnodes,
    nodesize = nodesize_vector
  )
  
  oob_error <- rf_model$OOBerror
  return(oob_error)
}

# Grid search
set.seed(123)
results <- data.frame()

for (i in 1:nrow(param_grid)) {
  params <- param_grid[i, ]
  
  # Evaluate model
  oob_error <- evaluate_rf_model(params$ntree, params$mtry, params$maxnodes, params$nodesize, impute_df)
  
  # Store the results
  results <- rbind(results, cbind(params, OOBerror = oob_error))
}

# Find best parameters
best_params <- results[which.min(results$OOBerror), ]
print(best_params)

#  Final Imputation with Best Parameters 
imp_result <- missForest(
  impute_df,
  ntree = best_params$ntree,
  mtry = best_params$mtry,
  maxnodes = best_params$maxnodes,
  nodesize = c(1,1),
  verbose = FALSE
)

#imp_result <- missForest(impute_df, verbose = FALSE)

long_df$HousePrice <- imp_result$ximp$HousePrice

write.csv(long_df, "long_hp_imputed.csv", row.names = FALSE)
long_df <- read.csv("long_hp_imputed.csv")

hp_imputed <- long_df

#  Pivot back to wide 
hp_wide <- hp_imputed %>%
  select(LSOA11CD, Period, HousePrice) %>%
  pivot_wider(names_from = Period, values_from = HousePrice)

#  Restore metadata 
hp_wide <- hp %>%
  select(LSOA11CD, LSOA.name, Local.authority.code, Local.authority.name) %>%
  left_join(hp_wide, by = "LSOA11CD")

# creating hp map

lsoa_with_hp <- lsoa_sf %>%
  left_join(hp_imputed, by = "LSOA11CD")  # Merging by LSOA11CD

library(ggplot2)

lsoa_with_hp <- st_as_sf(lsoa_with_hp)

# Create a heatmap of house prices across the LSOAs
ggplot(lsoa_with_hp) +
  geom_sf(aes(fill = HousePrice)) +  # Plot HousePrice as fill
  scale_fill_viridis_c(option = "plasma", 
  limits = c(0, 1000000)) +  # Use the plasma color scale
  labs(title = "Heatmap of Imputed House Prices by LSOA") +
  theme_minimal() +
  theme(legend.position = "right")

min(long_df$HousePrice)


write.csv(hp_wide, "hp_advanced_imputation_contiguous.csv", row.names = FALSE)
